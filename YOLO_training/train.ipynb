{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Download the dataset from\n",
    "https://www.kaggle.com/datasets/734b7bcb7ef13a045cbdd007a3c19874c2586ed0b02b4afc86126e89d00af8d2\n",
    "Store it as a folder called dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Label Formatting\n",
    "Clear all unused of deprecated files and folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from tqdm import tqdm  # For the progress bar\n",
    "\n",
    "# Path to the 'dataset' folder\n",
    "dataset_folder = \"dataset\"\n",
    "\n",
    "# List of folders to keep\n",
    "folders_to_keep = [\"images\", \"labels\"]\n",
    "\n",
    "# Iterate through all items in the dataset folder\n",
    "for item in os.listdir(dataset_folder):\n",
    "    item_path = os.path.join(dataset_folder, item)\n",
    "    \n",
    "    # Check if the item is not in the keep list\n",
    "    if item not in folders_to_keep:\n",
    "        # Remove the folder or file\n",
    "        if os.path.isdir(item_path):\n",
    "            shutil.rmtree(item_path)  # Remove directories\n",
    "            print(f\"Removed folder: {item_path}\")\n",
    "        else:\n",
    "            os.remove(item_path)  # Remove files\n",
    "            print(f\"Removed file: {item_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reformat dataset to include only vehicles.\n",
    "The original dataset contains the labels of:\n",
    "\n",
    "    [\"aeroplane\", \"bicyclebike\", \"bird\", \"boat\", \"bottle\", \"bus\",\n",
    "    \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\",\n",
    "    \"motorbike\", \"person\", \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n",
    "\n",
    "A new filtered label directory has been created so that only remain the vehicles:\n",
    "\n",
    "    [\"car\", \"bus\", \"motorbike\", \"bicyclebike\"]\n",
    "\n",
    "These new labels are stored in dataset/labels_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing YOLO label .txt files\n",
    "label_dir = \"dataset/labels\"  # Replace with your label directory path\n",
    "\n",
    "# Class IDs for vehicle-related objects based on CLASS_NAMES and their new mapping\n",
    "VEHICLE_CLASS_MAP = {\n",
    "    6: 0,  # car -> 0\n",
    "    5: 1,  # bus -> 1\n",
    "    13: 2, # motorbike -> 2\n",
    "    1: 3   # bicyclebike -> 3\n",
    "}\n",
    "\n",
    "# Directory to save filtered and remapped labels\n",
    "output_dir = \"dataset/labels_filtered\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def filter_and_remap_labels(label_file):\n",
    "    \"\"\"\n",
    "    Reads a YOLO label file, filters out non-vehicle classes,\n",
    "    remaps class IDs for vehicle classes, and writes the output to a new file.\n",
    "    \"\"\"\n",
    "    input_path = os.path.join(label_dir, label_file)\n",
    "    output_path = os.path.join(output_dir, label_file)\n",
    "\n",
    "    with open(input_path, \"r\") as infile, open(output_path, \"w\") as outfile:\n",
    "        for line in infile:\n",
    "            parts = line.split()\n",
    "            class_id = int(parts[0])  # Extract class ID\n",
    "            if class_id in VEHICLE_CLASS_MAP:\n",
    "                # Remap class ID and write the updated line\n",
    "                new_class_id = VEHICLE_CLASS_MAP[class_id]\n",
    "                outfile.write(f\"{new_class_id} \" + \" \".join(parts[1:]) + \"\\n\")\n",
    "\n",
    "# List all .txt files in the label directory\n",
    "label_files = [f for f in os.listdir(label_dir) if f.endswith(\".txt\")]\n",
    "\n",
    "# Process all .txt files with a progress bar\n",
    "with tqdm(total=len(label_files), desc=\"Processing Labels\", unit=\"file\") as pbar:\n",
    "    for file_name in label_files:\n",
    "        filter_and_remap_labels(file_name)\n",
    "        pbar.update(1)\n",
    "\n",
    "print(f\"Filtered and remapped labels saved in: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove empty labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the labels folder\n",
    "labels_folder = \"dataset/labels_filtered\"\n",
    "\n",
    "# List all .txt files in the labels folder\n",
    "label_files = [f for f in os.listdir(labels_folder) if f.endswith('.txt')]\n",
    "\n",
    "# Initialize a counter for removed files\n",
    "removed_count = 0\n",
    "\n",
    "# Check each label file and remove it if it's empty\n",
    "for label_file in label_files:\n",
    "    label_path = os.path.join(labels_folder, label_file)\n",
    "    if os.path.getsize(label_path) == 0:  # Check if the file size is 0 bytes\n",
    "        os.remove(label_path)  # Remove the empty file\n",
    "        removed_count += 1\n",
    "        # print(f\"Removed empty label: {label_file}\")\n",
    "\n",
    "# Output the result\n",
    "print(f\"Total empty labels removed: {removed_count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting images and filtered_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())\n",
    "# Define the paths to the images and labels folders\n",
    "images_folder = \"dataset/images\"\n",
    "labels_folder = \"dataset/labels_filtered\"\n",
    "\n",
    "# List all files in the images and labels folders\n",
    "image_files = [f for f in os.listdir(images_folder) if f.endswith('.jpg')]\n",
    "label_files = [f for f in os.listdir(labels_folder) if f.endswith('.txt')]\n",
    "\n",
    "# Count the total number of images and labels\n",
    "num_images = len(image_files)\n",
    "num_labels = len(label_files)\n",
    "\n",
    "# Check for matching files (base filenames without extensions)\n",
    "image_basenames = {os.path.splitext(f)[0] for f in image_files}\n",
    "label_basenames = {os.path.splitext(f)[0] for f in label_files}\n",
    "\n",
    "# Count matched and unmatched files\n",
    "matched_files = image_basenames & label_basenames\n",
    "unmatched_images = image_basenames - label_basenames\n",
    "unmatched_labels = label_basenames - image_basenames\n",
    "\n",
    "print(f\"Total images: {num_images}\")\n",
    "print(f\"Total labels: {num_labels}\")\n",
    "print(f\"Matched files: {len(matched_files)}\")\n",
    "print(f\"Unmatched images: {len(unmatched_images)}\")\n",
    "print(f\"Unmatched labels: {len(unmatched_labels)}\")\n",
    "\n",
    "# Optionally print the unmatched files\n",
    "if unmatched_images:\n",
    "    print(\"Unmatched images (no corresponding label):\")\n",
    "    for img in unmatched_images:\n",
    "        print(f\"  {img}\")\n",
    "\n",
    "if unmatched_labels:\n",
    "    print(\"Unmatched labels (no corresponding image):\")\n",
    "    for lbl in unmatched_labels:\n",
    "        print(f\"  {lbl}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the folder of images_filtered with a reduced number of unlabellel images.\n",
    "The ratio of labelled images and unlabelled images has been set to 50/50. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "images_folder = \"dataset/images\"\n",
    "labels_folder = \"dataset/labels_filtered\"\n",
    "output_folder = \"dataset/images_filtered\"\n",
    "\n",
    "# Ratio of labeled and unlabeled images\n",
    "r_label = 50\n",
    "r_unlabel = 100 - r_label\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Get all image files and corresponding label files\n",
    "image_files = [f for f in os.listdir(images_folder) if f.endswith('.jpg')]\n",
    "label_files = [f for f in os.listdir(labels_folder) if f.endswith('.txt')]\n",
    "\n",
    "# Get the base filenames (without extensions) for labels\n",
    "label_basenames = {os.path.splitext(label)[0] for label in label_files}\n",
    "\n",
    "# Separate labeled and unlabeled images\n",
    "labeled_images = [img for img in image_files if os.path.splitext(img)[0] in label_basenames]\n",
    "unlabeled_images = [img for img in image_files if os.path.splitext(img)[0] not in label_basenames]\n",
    "\n",
    "# Check counts\n",
    "num_labeled = len(labeled_images)\n",
    "num_unlabeled_to_select = min(int(num_labeled * r_unlabel / r_label), len(unlabeled_images))\n",
    "\n",
    "# Randomly select the required number of unlabeled images\n",
    "selected_unlabeled_images = random.sample(unlabeled_images, num_unlabeled_to_select)\n",
    "\n",
    "# Combine labeled and selected unlabeled images\n",
    "images_to_copy = labeled_images + selected_unlabeled_images\n",
    "\n",
    "# Copy labeled and selected unlabeled images to the output folder with a progress bar\n",
    "with tqdm(total=len(images_to_copy), desc=\"Copying Images\", unit=\"file\") as pbar:\n",
    "    for img in images_to_copy:\n",
    "        src_path = os.path.join(images_folder, img)\n",
    "        dst_path = os.path.join(output_folder, img)\n",
    "        shutil.copy(src_path, dst_path)\n",
    "        pbar.update(1)\n",
    "\n",
    "# Output results\n",
    "print(f\"Total labeled images: {num_labeled}\")\n",
    "print(f\"Total unlabeled images selected: {len(selected_unlabeled_images)}\")\n",
    "print(f\"Total images in 'images_filtered': {len(os.listdir(output_folder))}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Train, Validation and Test image sets\n",
    "From the image and labels (\"dataset/images\", \"dataset/labels_filtered\")\n",
    "Create the test, validation and test sets.\n",
    "\n",
    "\n",
    "- Training is stored in (\"dataset/train/images\", \"dataset/train/labels\")\n",
    "- Validation is stored in (\"dataset/valid/images\", \"dataset/valid/labels\")\n",
    "- Test is stored in (\"dataset/test/images\", \"dataset/test/labels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from tqdm import tqdm  # For progress bar\n",
    "\n",
    "# Split data into 60% train, 20% validation, 20% test\n",
    "train_perc = .6\n",
    "valid_perc = .2\n",
    "\n",
    "# Define folder paths\n",
    "images_folder = \"dataset/images_filtered\"  # Folder containing filtered images\n",
    "labels_folder = \"dataset/labels_filtered\"  # Folder containing filtered labels\n",
    "\n",
    "train_images_folder = \"dataset/train/images\"\n",
    "train_labels_folder = \"dataset/train/labels\"\n",
    "\n",
    "valid_images_folder = \"dataset/valid/images\"\n",
    "valid_labels_folder = \"dataset/valid/labels\"\n",
    "\n",
    "test_images_folder = \"dataset/test/images\"\n",
    "test_labels_folder = \"dataset/test/labels\"\n",
    "\n",
    "# Create output directories\n",
    "for folder in [train_images_folder, train_labels_folder,\n",
    "               valid_images_folder, valid_labels_folder,\n",
    "               test_images_folder, test_labels_folder]:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "# Get a list of all images\n",
    "image_files = sorted(os.listdir(images_folder))\n",
    "\n",
    "# Create a list of images with and without labels\n",
    "data = []\n",
    "for image_file in image_files:\n",
    "    label_file = os.path.splitext(image_file)[0] + \".txt\"\n",
    "    if os.path.exists(os.path.join(labels_folder, label_file)):\n",
    "        data.append((image_file, label_file))  # Image has a corresponding label\n",
    "    else:\n",
    "        data.append((image_file, None))  # Image has no label (no objects detected)\n",
    "\n",
    "# Shuffle the data\n",
    "random.shuffle(data)\n",
    "\n",
    "# Split data into ratios\n",
    "train_split = int(train_perc * len(data))\n",
    "valid_split = int((train_perc + valid_perc) * len(data))\n",
    "\n",
    "train_data = data[:train_split]\n",
    "valid_data = data[train_split:valid_split]\n",
    "test_data = data[valid_split:]\n",
    "\n",
    "# Function to copy images and labels with a progress bar\n",
    "def copy_files(data, dest_images_folder, dest_labels_folder, phase_name):\n",
    "    with tqdm(total=len(data), desc=f\"Copying {phase_name}\") as pbar:\n",
    "        for image_file, label_file in data:\n",
    "            # Copy the image file\n",
    "            shutil.copy(os.path.join(images_folder, image_file), os.path.join(dest_images_folder, image_file))\n",
    "            # Copy the label file if it exists\n",
    "            if label_file:\n",
    "                shutil.copy(os.path.join(labels_folder, label_file), os.path.join(dest_labels_folder, label_file))\n",
    "            # Update progress bar\n",
    "            pbar.update(1)\n",
    "\n",
    "# Copy data to respective folders\n",
    "copy_files(train_data, train_images_folder, train_labels_folder, \"Training Data\")\n",
    "copy_files(valid_data, valid_images_folder, valid_labels_folder, \"Validation Data\")\n",
    "copy_files(test_data, test_images_folder, test_labels_folder, \"Testing Data\")\n",
    "\n",
    "print(\"Dataset split complete!\")\n",
    "print(f\"Training data: {len(train_data)} images\")\n",
    "print(f\"Validation data: {len(valid_data)} images\")\n",
    "print(f\"Testing data: {len(test_data)} images\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load YOLO Model and Begin Training!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ultralytics \n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "epochs_per_run = 5\n",
    "\n",
    "path = os.getcwd()\n",
    "model_path = os.path.join(path, \"runs/detect/successful_train_25\", \"weights/best.pt\")\n",
    "\n",
    "i=0\n",
    "\n",
    "print(\"*********************\")\n",
    "print(\"*********************\")\n",
    "print(f'***Saved epoch {i}***')\n",
    "print(\"*********************\")\n",
    "print(\"*********************\")\n",
    "\n",
    "while 1:\n",
    "\n",
    "    # Load a pretrained YOLOv11 model\n",
    "    model = YOLO(model_path)  # Choose the appropriate model variant\n",
    "    \n",
    "    # Train the model\n",
    "    yaml_path = os.path.join(path, \"train.yaml\")\n",
    "    print(yaml_path)\n",
    "    out = model.train(\n",
    "        data=yaml_path,           # Path to the data configuration file\n",
    "        epochs=epochs_per_run,    # Number of training epochs\n",
    "        imgsz=640,                # Image size\n",
    "        batch=16,                 # Batch size\n",
    "        device=\"cpu\"              # GPU device (use 'cpu' for CPU training)\n",
    "    )\n",
    "\n",
    "    model_path = os.path.join(path, out.save_dir, \"weights/last.pt\")\n",
    "    i+=epochs_per_run\n",
    "    print(\"*********************\")\n",
    "    print(\"*********************\")\n",
    "    print(f'***Saved epoch {i}***')\n",
    "    print(\"*********************\")\n",
    "    print(\"*********************\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
