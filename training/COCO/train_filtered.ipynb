{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This file will be used to format the training set for the different tests\n",
    "\n",
    "We will begin by clearing folders that have been created by this same script. So we can get a fresh setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# !pip install -U ultralytics\n",
    "import ultralytics\n",
    "# from ultralytics import settings\n",
    "# # Get the current working directory\n",
    "# datasets_folder = os.path.join(os.getcwd(), \"datasets\")\n",
    "# # Update the datasets_dir setting with the actual path value\n",
    "# if not os.path.exists(datasets_folder):\n",
    "#     os.makedirs(datasets_folder)\n",
    "# settings.update({\"datasets_dir\": datasets_folder})\n",
    "!yolo checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Path to the 'datasets' folder\n",
    "dataset_folder = \"datasets\"\n",
    "\n",
    "# List of folders to keep (Modify this if needed)\n",
    "folders_to_keep = []  # Example: [\"images\", \"labels\"]\n",
    "\n",
    "# Check if the dataset folder exists\n",
    "if not os.path.exists(dataset_folder):\n",
    "    print(f\"Error: The folder '{dataset_folder}' does not exist.\")\n",
    "else:\n",
    "    # Iterate through all items in the dataset folder\n",
    "    for item in os.listdir(dataset_folder):\n",
    "        item_path = os.path.join(dataset_folder, item)\n",
    "        \n",
    "        # Check if the item is not in the keep list\n",
    "        if item not in folders_to_keep:\n",
    "            # Remove the folder or file\n",
    "            if os.path.isdir(item_path):\n",
    "                shutil.rmtree(item_path)  # Remove directories\n",
    "                print(f\"Removed folder: {item_path}\")\n",
    "            else:\n",
    "                os.remove(item_path)  # Remove files\n",
    "                print(f\"Removed file: {item_path}\")\n",
    "print(\"Cleanup completed.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code downloads the COCO dataset from github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.utils.downloads import download\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the dataset folder path\n",
    "dataset_dir = Path().parent / \"datasets\"  # Set dataset path relative to the script\n",
    "\n",
    "# Ensure the dataset folder exists\n",
    "dataset_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download labels\n",
    "segments = True  # segment or box labels\n",
    "url = 'https://github.com/ultralytics/assets/releases/download/v0.0.0/'\n",
    "urls = [url + ('coco2017labels-segments.zip' if segments else 'coco2017labels.zip')]  # labels\n",
    "download(urls, dir=dataset_dir / 'labels')\n",
    "\n",
    "# Download images\n",
    "urls = [\n",
    "    'http://images.cocodataset.org/zips/train2017.zip',  # 19G, 118k images\n",
    "    'http://images.cocodataset.org/zips/val2017.zip'  # 1G, 5k images\n",
    "    # ,'http://images.cocodataset.org/zips/test2017.zip'  # 7G, 41k images (optional)\n",
    "]\n",
    "download(urls, dir=dataset_dir / 'images', threads=3)\n",
    "\n",
    "print(f\"Labels saved to {dataset_dir / 'labels'}\")\n",
    "print(f\"Images saved to {dataset_dir / 'images'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image reordering\n",
    "Copies all the images from ~/datasets/coco into the /dataset folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define source directories\n",
    "coco_train_images = os.path.expanduser(\"datasets/images/train2017\")\n",
    "coco_val_images = os.path.expanduser(\"datasets/images/val2017\")\n",
    "coco_train_labels = os.path.expanduser(\"datasets/labels/coco/labels/train2017\")\n",
    "coco_val_labels = os.path.expanduser(\"datasets/labels/coco/labels/val2017\")\n",
    "\n",
    "# Define target directories\n",
    "dataset_images = \"datasets/images\"\n",
    "dataset_labels = \"datasets/labels\"\n",
    "\n",
    "# Ensure target directories exist\n",
    "os.makedirs(dataset_images, exist_ok=True)\n",
    "os.makedirs(dataset_labels, exist_ok=True)\n",
    "\n",
    "# Helper function to copy files\n",
    "def copy_files(source_dir, target_dir, file_extension, phase_name):\n",
    "    \"\"\"\n",
    "    Copy files with a specific extension from source_dir to target_dir.\n",
    "\n",
    "    Args:\n",
    "        source_dir (str): Source directory path.\n",
    "        target_dir (str): Target directory path.\n",
    "        file_extension (str): File extension to filter.\n",
    "        phase_name (str): Name of the phase (e.g., 'train', 'val') for progress.\n",
    "    \"\"\"\n",
    "    files = [f for f in os.listdir(source_dir) if f.endswith(file_extension)]\n",
    "    \n",
    "    with tqdm(total=len(files), desc=f\"Copying {phase_name} files\", unit=\"file\") as pbar:\n",
    "        for file_name in files:\n",
    "            src_path = os.path.relpath(os.path.join(source_dir, file_name))\n",
    "            dst_path = os.path.relpath(os.path.join(target_dir, file_name))\n",
    "            shutil.move(src_path, dst_path)\n",
    "            pbar.update(1)\n",
    "\n",
    "# Copy files\n",
    "copy_files(coco_train_images, dataset_images, \".jpg\", \"Training Images\")\n",
    "copy_files(coco_val_images, dataset_images, \".jpg\", \"Validation Images\")\n",
    "copy_files(coco_train_labels, dataset_labels, \".txt\", \"Training Labels\")\n",
    "copy_files(coco_val_labels, dataset_labels, \".txt\", \"Validation Labels\")\n",
    "\n",
    "print(\"Files successfully copied to dataset/images and dataset/labels with relative paths.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clear unused files that have been downloaded from the COCO dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Directories to clean\n",
    "directories = [\n",
    "    \"datasets/images\",\n",
    "    \"datasets/labels\"\n",
    "]\n",
    "\n",
    "def clean_directory(directory, extensions=[\".jpg\", \".txt\"]):\n",
    "    \"\"\"\n",
    "    Removes all files and folders from a directory except those with the specified extensions.\n",
    "    \n",
    "    Args:\n",
    "        directory (str): The directory to clean.\n",
    "        extensions (list): The file extensions to keep (default: [\".jpg\", \".txt\"]).\n",
    "    \"\"\"\n",
    "    for item in os.listdir(directory):\n",
    "        item_path = os.path.join(directory, item)\n",
    "        # Check if the item is a file and doesn't have a desired extension\n",
    "        if os.path.isfile(item_path) and not any(item.lower().endswith(ext) for ext in extensions):\n",
    "            os.remove(item_path)  # Remove the file\n",
    "        # If the item is a folder, remove it\n",
    "        elif os.path.isdir(item_path):\n",
    "            for root, dirs, files in os.walk(item_path, topdown=False):\n",
    "                for name in files:\n",
    "                    os.remove(os.path.join(root, name))\n",
    "                for name in dirs:\n",
    "                    os.rmdir(os.path.join(root, name))\n",
    "            os.rmdir(item_path)  # Remove the directory itself\n",
    "\n",
    "# Clean each directory\n",
    "for directory in directories:\n",
    "    if os.path.exists(directory):\n",
    "        clean_directory(directory)\n",
    "        print(f\"Cleaned directory: {directory}\")\n",
    "    else:\n",
    "        print(f\"Directory does not exist: {directory}\")\n",
    "\n",
    "print(\"Cleaning complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformat dataset to include only vehicles.\n",
    "The original dataset contains the labels of:\n",
    "\n",
    "    [\"aeroplane\", \"bicyclebike\", \"bird\", \"boat\", \"bottle\", \"bus\",\n",
    "    \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\",\n",
    "    \"motorbike\", \"person\", \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n",
    "\n",
    "A new filtered label directory has been created so that only remain the vehicles:\n",
    "\n",
    "    [\"car\", \"bus\", \"motorbike\", \"bicyclebike\"]\n",
    "\n",
    "These new labels are stored in dataset/labels_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Directory containing YOLO label .txt files\n",
    "label_dir = \"datasets/labels\"  # Replace with your label directory path\n",
    "\n",
    "# Mapping of original class IDs to new class IDs\n",
    "CLASS_MAPPING = {0: 0, 1: 1, 2: 2, 3: 3, 5: 4, 6: 5, 7: 6}\n",
    "\n",
    "# Directory to save filtered labels\n",
    "output_dir = \"datasets/labels_filtered\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def filter_and_map_labels(label_file):\n",
    "    \"\"\"\n",
    "    Reads a YOLO label file, filters out unwanted classes,\n",
    "    maps allowed classes to new values, and writes the updated labels to a new file.\n",
    "    \"\"\"\n",
    "    input_path = os.path.join(label_dir, label_file)\n",
    "    output_path = os.path.join(output_dir, label_file)\n",
    "\n",
    "    with open(input_path, \"r\") as infile, open(output_path, \"w\") as outfile:\n",
    "        for line in infile:\n",
    "            parts = line.split()\n",
    "            class_id = int(parts[0])  # Extract class ID\n",
    "\n",
    "            if class_id in CLASS_MAPPING:\n",
    "                new_class_id = CLASS_MAPPING[class_id]\n",
    "                # Replace class ID and write the updated line\n",
    "                outfile.write(f\"{new_class_id} \" + \" \".join(parts[1:]) + \"\\n\")\n",
    "\n",
    "# List all .txt files in the label directory\n",
    "label_files = [f for f in os.listdir(label_dir) if f.endswith(\".txt\")]\n",
    "\n",
    "# Process all .txt files with a progress bar\n",
    "with tqdm(total=len(label_files), desc=\"Filtering & Mapping Labels\", unit=\"file\") as pbar:\n",
    "    for file_name in label_files:\n",
    "        filter_and_map_labels(file_name)\n",
    "        pbar.update(1)\n",
    "\n",
    "print(f\"Filtered and mapped labels saved in: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove empty labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the labels folder\n",
    "labels_folder = \"datasets/labels_filtered\"\n",
    "\n",
    "# List all .txt files in the labels folder\n",
    "label_files = [f for f in os.listdir(labels_folder) if f.endswith('.txt')]\n",
    "\n",
    "# Initialize a counter for removed files\n",
    "removed_count = 0\n",
    "\n",
    "# Check each label file and remove it if it's empty\n",
    "for label_file in label_files:\n",
    "    label_path = os.path.join(labels_folder, label_file)\n",
    "    if os.path.getsize(label_path) == 0:  # Check if the file size is 0 bytes\n",
    "        os.remove(label_path)  # Remove the empty file\n",
    "        removed_count += 1\n",
    "        # print(f\"Removed empty label: {label_file}\")\n",
    "\n",
    "# Output the result\n",
    "print(f\"Total empty labels removed: {removed_count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting images and filtered_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())\n",
    "# Define the paths to the images and labels folders\n",
    "images_folder = \"datasets/images\"\n",
    "labels_folder = \"datasets/labels_filtered\"\n",
    "\n",
    "# List all files in the images and labels folders\n",
    "image_files = [f for f in os.listdir(images_folder) if f.endswith('.jpg')]\n",
    "label_files = [f for f in os.listdir(labels_folder) if f.endswith('.txt')]\n",
    "\n",
    "# Count the total number of images and labels\n",
    "num_images = len(image_files)\n",
    "num_labels = len(label_files)\n",
    "\n",
    "# Check for matching files (base filenames without extensions)\n",
    "image_basenames = {os.path.splitext(f)[0] for f in image_files}\n",
    "label_basenames = {os.path.splitext(f)[0] for f in label_files}\n",
    "\n",
    "# Count matched and unmatched files\n",
    "matched_files = image_basenames & label_basenames\n",
    "unmatched_images = image_basenames - label_basenames\n",
    "unmatched_labels = label_basenames - image_basenames\n",
    "\n",
    "print(f\"Total images: {num_images}\")\n",
    "print(f\"Total labels: {num_labels}\")\n",
    "print(f\"Matched files: {len(matched_files)}\")\n",
    "print(f\"Unmatched images: {len(unmatched_images)}\")\n",
    "print(f\"Unmatched labels: {len(unmatched_labels)}\")\n",
    "\n",
    "# Optionally print the unmatched files\n",
    "# if unmatched_images:\n",
    "#     print(\"Unmatched images (no corresponding label):\")\n",
    "#     for img in unmatched_images:\n",
    "#         # print(f\"  {img}\")\n",
    "\n",
    "# if unmatched_labels:\n",
    "#     print(\"Unmatched labels (no corresponding image):\")\n",
    "#     for lbl in unmatched_labels:\n",
    "#         # print(f\"  {lbl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the folder of images_filtered with a reduced number of unlabellel images.\n",
    "The ratio of labelled images and unlabelled images has been set to 50/50. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Paths\n",
    "images_folder = \"datasets/images\"\n",
    "labels_folder = \"datasets/labels_filtered\"\n",
    "output_folder = \"datasets/images_filtered\"\n",
    "\n",
    "# Ratio of labeled and unlabeled images\n",
    "r_label = 50\n",
    "r_unlabel = 100 - r_label\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Get all image files and corresponding label files\n",
    "image_files = [f for f in os.listdir(images_folder) if f.endswith('.jpg')]\n",
    "label_files = [f for f in os.listdir(labels_folder) if f.endswith('.txt')]\n",
    "\n",
    "# Get the base filenames (without extensions) for labels\n",
    "label_basenames = {os.path.splitext(label)[0] for label in label_files}\n",
    "\n",
    "# Separate labeled and unlabeled images\n",
    "labeled_images = [img for img in image_files if os.path.splitext(img)[0] in label_basenames]\n",
    "unlabeled_images = [img for img in image_files if os.path.splitext(img)[0] not in label_basenames]\n",
    "\n",
    "# Check counts\n",
    "num_labeled = len(labeled_images)\n",
    "num_unlabeled_to_select = min(int(num_labeled * r_unlabel / r_label), len(unlabeled_images))\n",
    "\n",
    "# Randomly select the required number of unlabeled images\n",
    "selected_unlabeled_images = random.sample(unlabeled_images, num_unlabeled_to_select)\n",
    "\n",
    "# Combine labeled and selected unlabeled images\n",
    "images_to_copy = labeled_images + selected_unlabeled_images\n",
    "\n",
    "# Copy labeled and selected unlabeled images to the output folder with a progress bar\n",
    "with tqdm(total=len(images_to_copy), desc=\"Copying Images\", unit=\"file\") as pbar:\n",
    "    for img in images_to_copy:\n",
    "        src_path = os.path.join(images_folder, img)\n",
    "        dst_path = os.path.join(output_folder, img)\n",
    "        shutil.copy(src_path, dst_path)\n",
    "        pbar.update(1)\n",
    "\n",
    "# Output results\n",
    "print(f\"Total labeled images: {num_labeled}\")\n",
    "print(f\"Total unlabeled images selected: {len(selected_unlabeled_images)}\")\n",
    "print(f\"Total images in 'images_filtered': {len(os.listdir(output_folder))}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting Class Frequencies: 100%|██████████| 74784/74784 [08:10<00:00, 152.44file/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most common class: 0 (Threshold: 90898)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering Dominant Class Images: 100%|██████████| 74784/74784 [00:27<00:00, 2735.21file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removed 51048 images where only class 0 was present.\n",
      "Final count of class 0: 216981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Paths\n",
    "images_folder = \"datasets/images\"\n",
    "labels_folder = \"datasets/labels_filtered\"\n",
    "\n",
    "# Step 1: Count class occurrences across all label files\n",
    "class_counts = defaultdict(int)\n",
    "file_classes = {}  # Store classes per file\n",
    "\n",
    "# Get label files\n",
    "label_files = [f for f in os.listdir(labels_folder) if f.endswith(\".txt\")]\n",
    "\n",
    "for label_file in tqdm(label_files, desc=\"Counting Class Frequencies\", unit=\"file\"):\n",
    "    label_path = os.path.join(labels_folder, label_file)\n",
    "    with open(label_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    # Store class IDs present in this file\n",
    "    file_classes[label_file] = set()\n",
    "    \n",
    "    for line in lines:\n",
    "        class_id = int(line.split()[0])  # Extract class ID\n",
    "        class_counts[class_id] += 1\n",
    "        file_classes[label_file].add(class_id)\n",
    "\n",
    "# Step 2: Identify dominant class and second most common class\n",
    "sorted_classes = sorted(class_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "most_common_class = sorted_classes[0][0]  # Most frequent class\n",
    "second_most_common_class_count = sorted_classes[1][1]  # Count of second most frequent class\n",
    "\n",
    "# Define threshold for most common class\n",
    "threshold = 2 * second_most_common_class_count\n",
    "print(f\"\\nMost common class: {most_common_class} (Threshold: {threshold})\")\n",
    "\n",
    "# Step 3: Remove images where only the most common class exists\n",
    "removed_files = 0\n",
    "for label_file, classes in tqdm(file_classes.items(), desc=\"Filtering Dominant Class Images\", unit=\"file\"):\n",
    "    if most_common_class in classes and len(classes) == 1:  # Only contains the dominant class\n",
    "        # Remove corresponding image and label\n",
    "        label_path = os.path.join(labels_folder, label_file)\n",
    "        image_path = os.path.join(images_folder, label_file.replace(\".txt\", \".jpg\"))  # Assuming .jpg images\n",
    "        \n",
    "        os.remove(label_path)\n",
    "        if os.path.exists(image_path):\n",
    "            os.remove(image_path)\n",
    "        \n",
    "        removed_files += 1\n",
    "        class_counts[most_common_class] -= len(classes)  # Reduce count\n",
    "\n",
    "        # Stop removing once threshold is met\n",
    "        if class_counts[most_common_class] <= threshold:\n",
    "            break\n",
    "\n",
    "print(f\"\\nRemoved {removed_files} images where only class {most_common_class} was present.\")\n",
    "print(f\"Final count of class {most_common_class}: {class_counts[most_common_class]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Train, Validation and Test image sets\n",
    "From the image and labels (\"dataset/images\", \"dataset/labels_filtered\")\n",
    "Create the test, validation and test sets.\n",
    "\n",
    "\n",
    "- Training is stored in (\"dataset/train/images\", \"dataset/train/labels\")\n",
    "- Validation is stored in (\"dataset/valid/images\", \"dataset/valid/labels\")\n",
    "- Test is stored in (\"dataset/test/images\", \"dataset/test/labels\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code takes the unfiltered images and create the corresponding training, validation and test set in the following folders:\n",
    "- dataset/train\n",
    "- dataset/valid\n",
    "- dataset/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "# import random\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # Split data into 20% train, 5% validation, and 5% test\n",
    "# train_perc = 0.8\n",
    "# valid_perc = 0.1\n",
    "# test_perc = 0.1\n",
    "\n",
    "# # Define folder paths\n",
    "# images_folder = \"datasets/images\"  # Folder containing filtered images\n",
    "# labels_folder = \"datasets/labels\"  # Folder containing filtered labels\n",
    "\n",
    "# train_images_folder = \"datasets/train/images\"\n",
    "# train_labels_folder = \"datasets/train/labels\"\n",
    "\n",
    "# valid_images_folder = \"datasets/valid/images\"\n",
    "# valid_labels_folder = \"datasets/valid/labels\"\n",
    "\n",
    "# test_images_folder = \"datasets/test/images\"\n",
    "# test_labels_folder = \"datasets/test/labels\"\n",
    "\n",
    "# # Create output directories\n",
    "# for folder in [train_images_folder, train_labels_folder,\n",
    "#                valid_images_folder, valid_labels_folder,\n",
    "#                test_images_folder, test_labels_folder]:\n",
    "#     if os.path.exists(folder):\n",
    "#         # Remove the folder and its contents\n",
    "#         shutil.rmtree(folder, ignore_errors=True)\n",
    "    \n",
    "#     os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "# # Get a list of all images\n",
    "# image_files = sorted(os.listdir(images_folder))\n",
    "\n",
    "# # Create a list of images with and without labels\n",
    "# data = []\n",
    "# for image_file in image_files:\n",
    "#     label_file = os.path.splitext(image_file)[0] + \".txt\"\n",
    "#     if os.path.exists(os.path.join(labels_folder, label_file)):\n",
    "#         data.append((image_file, label_file))  # Image has a corresponding label\n",
    "#     else:\n",
    "#         data.append((image_file, None))  # Image has no label (no objects detected)\n",
    "\n",
    "# # Shuffle the data\n",
    "# random.shuffle(data)\n",
    "\n",
    "# # Calculate splits\n",
    "# total_data = len(data)\n",
    "# train_split = int(train_perc * total_data)\n",
    "# valid_split = train_split + int(valid_perc * total_data)\n",
    "# test_split = valid_split + int(test_perc * total_data)\n",
    "\n",
    "# # Allocate data\n",
    "# train_data = data[:train_split]\n",
    "# valid_data = data[train_split:valid_split]\n",
    "# test_data = data[valid_split:test_split]\n",
    "\n",
    "# # Function to copy images and labels with a progress bar\n",
    "# def copy_files(data, dest_images_folder, dest_labels_folder, phase_name):\n",
    "#     with tqdm(total=len(data), desc=f\"Copying {phase_name}\") as pbar:\n",
    "#         for image_file, label_file in data:\n",
    "#             # Copy the image file\n",
    "#             shutil.copy(os.path.join(images_folder, image_file), os.path.join(dest_images_folder, image_file))\n",
    "#             # Copy the label file if it exists\n",
    "#             if label_file:\n",
    "#                 shutil.copy(os.path.join(labels_folder, label_file), os.path.join(dest_labels_folder, label_file))\n",
    "#             # Update progress bar\n",
    "#             pbar.update(1)\n",
    "\n",
    "# # Copy data to respective folders\n",
    "# copy_files(train_data, train_images_folder, train_labels_folder, \"Training Data\")\n",
    "# copy_files(valid_data, valid_images_folder, valid_labels_folder, \"Validation Data\")\n",
    "# copy_files(test_data, test_images_folder, test_labels_folder, \"Testing Data\")\n",
    "\n",
    "# print(\"Dataset split complete!\")\n",
    "# print(f\"Training data: {len(train_data)} images\")\n",
    "# print(f\"Validation data: {len(valid_data)} images\")\n",
    "# print(f\"Testing data: {len(test_data)} images\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code takes the filtered images and create the corresponding training, validation and test set in the following folders:\n",
    "- dataset/train_filtered\n",
    "- dataset/valid_filtered\n",
    "- dataset/test_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Split data into 20% train, 5% validation, and 5% test\n",
    "train_perc = 0.8\n",
    "valid_perc = 0.1\n",
    "test_perc = 0.1\n",
    "\n",
    "# Define folder paths\n",
    "images_folder = \"datasets/images_filtered\"  # Folder containing filtered images\n",
    "labels_folder = \"datasets/labels_filtered\"  # Folder containing filtered labels\n",
    "\n",
    "train_images_folder = \"datasets/train_filtered/images\"\n",
    "train_labels_folder = \"datasets/train_filtered/labels\"\n",
    "\n",
    "valid_images_folder = \"datasets/valid_filtered/images\"\n",
    "valid_labels_folder = \"datasets/valid_filtered/labels\"\n",
    "\n",
    "test_images_folder = \"datasets/test_filtered/images\"\n",
    "test_labels_folder = \"datasets/test_filtered/labels\"\n",
    "\n",
    "# Create output directories\n",
    "for folder in [train_images_folder, train_labels_folder,\n",
    "               valid_images_folder, valid_labels_folder,\n",
    "               test_images_folder, test_labels_folder]:\n",
    "    if os.path.exists(folder):\n",
    "        # Remove the folder and its contents\n",
    "        shutil.rmtree(folder, ignore_errors=True)\n",
    "    \n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "# Get a list of all images\n",
    "image_files = sorted(os.listdir(images_folder))\n",
    "\n",
    "# Create a list of images with and without labels\n",
    "data = []\n",
    "for image_file in image_files:\n",
    "    label_file = os.path.splitext(image_file)[0] + \".txt\"\n",
    "    if os.path.exists(os.path.join(labels_folder, label_file)):\n",
    "        data.append((image_file, label_file))  # Image has a corresponding label\n",
    "    else:\n",
    "        data.append((image_file, None))  # Image has no label (no objects detected)\n",
    "\n",
    "# Shuffle the data\n",
    "random.shuffle(data)\n",
    "\n",
    "# Calculate splits\n",
    "total_data = len(data)\n",
    "train_split = int(train_perc * total_data)\n",
    "valid_split = train_split + int(valid_perc * total_data)\n",
    "test_split = valid_split + int(test_perc * total_data)\n",
    "\n",
    "# Allocate data\n",
    "train_data = data[:train_split]\n",
    "valid_data = data[train_split:valid_split]\n",
    "test_data = data[valid_split:test_split]\n",
    "\n",
    "# Function to copy images and labels with a progress bar\n",
    "def copy_files(data, dest_images_folder, dest_labels_folder, phase_name):\n",
    "    with tqdm(total=len(data), desc=f\"Copying {phase_name}\") as pbar:\n",
    "        for image_file, label_file in data:\n",
    "            # Copy the image file\n",
    "            shutil.copy(os.path.join(images_folder, image_file), os.path.join(dest_images_folder, image_file))\n",
    "            # Copy the label file if it exists\n",
    "            if label_file:\n",
    "                shutil.copy(os.path.join(labels_folder, label_file), os.path.join(dest_labels_folder, label_file))\n",
    "            # Update progress bar\n",
    "            pbar.update(1)\n",
    "\n",
    "# Copy data to respective folders\n",
    "copy_files(train_data, train_images_folder, train_labels_folder, \"Training Data\")\n",
    "copy_files(valid_data, valid_images_folder, valid_labels_folder, \"Validation Data\")\n",
    "copy_files(test_data, test_images_folder, test_labels_folder, \"Testing Data\")\n",
    "\n",
    "print(\"Dataset split complete!\")\n",
    "print(f\"Training data: {len(train_data)} images\")\n",
    "print(f\"Validation data: {len(valid_data)} images\")\n",
    "print(f\"Testing data: {len(test_data)} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing datasets/labels: 100%|██████████| 122218/122218 [10:56<00:00, 186.06file/s]\n",
      "Processing datasets/train/labels: 100%|██████████| 97775/97775 [10:24<00:00, 156.47file/s]\n",
      "Processing datasets/valid/labels: 100%|██████████| 12217/12217 [01:22<00:00, 147.20file/s]\n",
      "Processing datasets/test/labels: 100%|██████████| 12224/12224 [01:11<00:00, 170.86file/s]\n",
      "Processing datasets/labels_filtered: 100%|██████████| 74784/74784 [07:25<00:00, 167.84file/s]\n",
      "Processing datasets/train_filtered/labels: 100%|██████████| 59806/59806 [06:08<00:00, 162.23file/s]\n",
      "Processing datasets/valid_filtered/labels: 100%|██████████| 7504/7504 [00:40<00:00, 183.19file/s]\n",
      "Processing datasets/test_filtered/labels: 100%|██████████| 7473/7473 [00:43<00:00, 170.27file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class counts per directory:\n",
      "\n",
      "Directory: datasets/labels\n",
      "  Class 0: 268029\n",
      "  Class 1: 7370\n",
      "  Class 2: 45449\n",
      "  Class 3: 9021\n",
      "  Class 4: 5272\n",
      "  Class 5: 6344\n",
      "  Class 6: 4760\n",
      "  Class 7: 10384\n",
      "  Class 8: 11000\n",
      "  Class 9: 13476\n",
      "  Class 10: 1966\n",
      "  Class 11: 2058\n",
      "  Class 12: 1343\n",
      "  Class 13: 10231\n",
      "  Class 14: 10969\n",
      "  Class 15: 4968\n",
      "  Class 16: 5718\n",
      "  Class 17: 6839\n",
      "  Class 18: 9577\n",
      "  Class 19: 8386\n",
      "  Class 20: 5736\n",
      "  Class 21: 1365\n",
      "  Class 22: 5535\n",
      "  Class 23: 5360\n",
      "  Class 24: 9084\n",
      "  Class 25: 11672\n",
      "  Class 26: 12882\n",
      "  Class 27: 6700\n",
      "  Class 28: 6411\n",
      "  Class 29: 2796\n",
      "  Class 30: 6864\n",
      "  Class 31: 2750\n",
      "  Class 32: 6559\n",
      "  Class 33: 9129\n",
      "  Class 34: 3418\n",
      "  Class 35: 3895\n",
      "  Class 36: 5715\n",
      "  Class 37: 6362\n",
      "  Class 38: 5032\n",
      "  Class 39: 25083\n",
      "  Class 40: 8180\n",
      "  Class 41: 21469\n",
      "  Class 42: 5689\n",
      "  Class 43: 8085\n",
      "  Class 44: 6412\n",
      "  Class 45: 14946\n",
      "  Class 46: 9565\n",
      "  Class 47: 6012\n",
      "  Class 48: 4533\n",
      "  Class 49: 6587\n",
      "  Class 50: 7573\n",
      "  Class 51: 8123\n",
      "  Class 52: 3008\n",
      "  Class 53: 6091\n",
      "  Class 54: 7333\n",
      "  Class 55: 6606\n",
      "  Class 56: 39844\n",
      "  Class 57: 6040\n",
      "  Class 58: 8973\n",
      "  Class 59: 4355\n",
      "  Class 60: 16389\n",
      "  Class 61: 4328\n",
      "  Class 62: 6091\n",
      "  Class 63: 5190\n",
      "  Class 64: 2367\n",
      "  Class 65: 5983\n",
      "  Class 66: 3007\n",
      "  Class 67: 6684\n",
      "  Class 68: 1727\n",
      "  Class 69: 3477\n",
      "  Class 70: 234\n",
      "  Class 71: 5834\n",
      "  Class 72: 2760\n",
      "  Class 73: 25206\n",
      "  Class 74: 6587\n",
      "  Class 75: 6851\n",
      "  Class 76: 1500\n",
      "  Class 77: 4919\n",
      "  Class 78: 209\n",
      "  Class 79: 2002\n",
      "\n",
      "Directory: datasets/train/labels\n",
      "  Class 0: 214292\n",
      "  Class 1: 5883\n",
      "  Class 2: 36016\n",
      "  Class 3: 7183\n",
      "  Class 4: 4267\n",
      "  Class 5: 5062\n",
      "  Class 6: 3811\n",
      "  Class 7: 8293\n",
      "  Class 8: 8857\n",
      "  Class 9: 10709\n",
      "  Class 10: 1562\n",
      "  Class 11: 1665\n",
      "  Class 12: 1058\n",
      "  Class 13: 8122\n",
      "  Class 14: 8796\n",
      "  Class 15: 4032\n",
      "  Class 16: 4628\n",
      "  Class 17: 5364\n",
      "  Class 18: 7674\n",
      "  Class 19: 6736\n",
      "  Class 20: 4605\n",
      "  Class 21: 1090\n",
      "  Class 22: 4435\n",
      "  Class 23: 4350\n",
      "  Class 24: 7193\n",
      "  Class 25: 9311\n",
      "  Class 26: 10424\n",
      "  Class 27: 5245\n",
      "  Class 28: 5194\n",
      "  Class 29: 2239\n",
      "  Class 30: 5458\n",
      "  Class 31: 2161\n",
      "  Class 32: 5194\n",
      "  Class 33: 7297\n",
      "  Class 34: 2767\n",
      "  Class 35: 3082\n",
      "  Class 36: 4548\n",
      "  Class 37: 5191\n",
      "  Class 38: 4026\n",
      "  Class 39: 19868\n",
      "  Class 40: 6325\n",
      "  Class 41: 16817\n",
      "  Class 42: 4544\n",
      "  Class 43: 6464\n",
      "  Class 44: 5096\n",
      "  Class 45: 11942\n",
      "  Class 46: 7640\n",
      "  Class 47: 4751\n",
      "  Class 48: 3620\n",
      "  Class 49: 5272\n",
      "  Class 50: 6015\n",
      "  Class 51: 6455\n",
      "  Class 52: 2409\n",
      "  Class 53: 4844\n",
      "  Class 54: 5775\n",
      "  Class 55: 5247\n",
      "  Class 56: 31888\n",
      "  Class 57: 4857\n",
      "  Class 58: 7255\n",
      "  Class 59: 3482\n",
      "  Class 60: 13059\n",
      "  Class 61: 3463\n",
      "  Class 62: 4894\n",
      "  Class 63: 4146\n",
      "  Class 64: 1899\n",
      "  Class 65: 4809\n",
      "  Class 66: 2407\n",
      "  Class 67: 5294\n",
      "  Class 68: 1364\n",
      "  Class 69: 2762\n",
      "  Class 70: 186\n",
      "  Class 71: 4615\n",
      "  Class 72: 2219\n",
      "  Class 73: 20504\n",
      "  Class 74: 5194\n",
      "  Class 75: 5584\n",
      "  Class 76: 1173\n",
      "  Class 77: 3916\n",
      "  Class 78: 159\n",
      "  Class 79: 1621\n",
      "\n",
      "Directory: datasets/valid/labels\n",
      "  Class 0: 26961\n",
      "  Class 1: 697\n",
      "  Class 2: 4778\n",
      "  Class 3: 948\n",
      "  Class 4: 540\n",
      "  Class 5: 688\n",
      "  Class 6: 445\n",
      "  Class 7: 1058\n",
      "  Class 8: 1116\n",
      "  Class 9: 1344\n",
      "  Class 10: 192\n",
      "  Class 11: 211\n",
      "  Class 12: 161\n",
      "  Class 13: 1034\n",
      "  Class 14: 1075\n",
      "  Class 15: 432\n",
      "  Class 16: 558\n",
      "  Class 17: 697\n",
      "  Class 18: 1065\n",
      "  Class 19: 921\n",
      "  Class 20: 557\n",
      "  Class 21: 142\n",
      "  Class 22: 562\n",
      "  Class 23: 530\n",
      "  Class 24: 937\n",
      "  Class 25: 1215\n",
      "  Class 26: 1294\n",
      "  Class 27: 662\n",
      "  Class 28: 630\n",
      "  Class 29: 305\n",
      "  Class 30: 740\n",
      "  Class 31: 290\n",
      "  Class 32: 698\n",
      "  Class 33: 942\n",
      "  Class 34: 323\n",
      "  Class 35: 382\n",
      "  Class 36: 570\n",
      "  Class 37: 631\n",
      "  Class 38: 556\n",
      "  Class 39: 2513\n",
      "  Class 40: 907\n",
      "  Class 41: 2356\n",
      "  Class 42: 532\n",
      "  Class 43: 823\n",
      "  Class 44: 626\n",
      "  Class 45: 1563\n",
      "  Class 46: 959\n",
      "  Class 47: 643\n",
      "  Class 48: 458\n",
      "  Class 49: 734\n",
      "  Class 50: 715\n",
      "  Class 51: 903\n",
      "  Class 52: 306\n",
      "  Class 53: 560\n",
      "  Class 54: 750\n",
      "  Class 55: 658\n",
      "  Class 56: 3979\n",
      "  Class 57: 575\n",
      "  Class 58: 917\n",
      "  Class 59: 427\n",
      "  Class 60: 1677\n",
      "  Class 61: 433\n",
      "  Class 62: 548\n",
      "  Class 63: 536\n",
      "  Class 64: 208\n",
      "  Class 65: 573\n",
      "  Class 66: 278\n",
      "  Class 67: 696\n",
      "  Class 68: 180\n",
      "  Class 69: 364\n",
      "  Class 70: 24\n",
      "  Class 71: 609\n",
      "  Class 72: 275\n",
      "  Class 73: 2272\n",
      "  Class 74: 706\n",
      "  Class 75: 636\n",
      "  Class 76: 183\n",
      "  Class 77: 465\n",
      "  Class 78: 27\n",
      "  Class 79: 165\n",
      "\n",
      "Directory: datasets/test/labels\n",
      "  Class 0: 26764\n",
      "  Class 1: 790\n",
      "  Class 2: 4654\n",
      "  Class 3: 890\n",
      "  Class 4: 465\n",
      "  Class 5: 592\n",
      "  Class 6: 504\n",
      "  Class 7: 1033\n",
      "  Class 8: 1027\n",
      "  Class 9: 1423\n",
      "  Class 10: 212\n",
      "  Class 11: 182\n",
      "  Class 12: 124\n",
      "  Class 13: 1075\n",
      "  Class 14: 1098\n",
      "  Class 15: 504\n",
      "  Class 16: 532\n",
      "  Class 17: 778\n",
      "  Class 18: 838\n",
      "  Class 19: 729\n",
      "  Class 20: 574\n",
      "  Class 21: 132\n",
      "  Class 22: 538\n",
      "  Class 23: 480\n",
      "  Class 24: 954\n",
      "  Class 25: 1146\n",
      "  Class 26: 1162\n",
      "  Class 27: 792\n",
      "  Class 28: 587\n",
      "  Class 29: 252\n",
      "  Class 30: 666\n",
      "  Class 31: 299\n",
      "  Class 32: 667\n",
      "  Class 33: 890\n",
      "  Class 34: 328\n",
      "  Class 35: 431\n",
      "  Class 36: 597\n",
      "  Class 37: 540\n",
      "  Class 38: 450\n",
      "  Class 39: 2702\n",
      "  Class 40: 948\n",
      "  Class 41: 2296\n",
      "  Class 42: 613\n",
      "  Class 43: 798\n",
      "  Class 44: 690\n",
      "  Class 45: 1441\n",
      "  Class 46: 966\n",
      "  Class 47: 618\n",
      "  Class 48: 455\n",
      "  Class 49: 581\n",
      "  Class 50: 843\n",
      "  Class 51: 765\n",
      "  Class 52: 293\n",
      "  Class 53: 687\n",
      "  Class 54: 808\n",
      "  Class 55: 701\n",
      "  Class 56: 3977\n",
      "  Class 57: 608\n",
      "  Class 58: 801\n",
      "  Class 59: 446\n",
      "  Class 60: 1653\n",
      "  Class 61: 432\n",
      "  Class 62: 649\n",
      "  Class 63: 508\n",
      "  Class 64: 260\n",
      "  Class 65: 601\n",
      "  Class 66: 322\n",
      "  Class 67: 694\n",
      "  Class 68: 183\n",
      "  Class 69: 351\n",
      "  Class 70: 24\n",
      "  Class 71: 610\n",
      "  Class 72: 266\n",
      "  Class 73: 2430\n",
      "  Class 74: 687\n",
      "  Class 75: 631\n",
      "  Class 76: 144\n",
      "  Class 77: 538\n",
      "  Class 78: 23\n",
      "  Class 79: 216\n",
      "\n",
      "Directory: datasets/labels_filtered\n",
      "  Class 0: 268029\n",
      "  Class 1: 7370\n",
      "  Class 2: 45449\n",
      "  Class 3: 9021\n",
      "  Class 4: 6344\n",
      "  Class 5: 4760\n",
      "  Class 6: 10384\n",
      "\n",
      "Directory: datasets/train_filtered/labels\n",
      "  Class 0: 214627\n",
      "  Class 1: 5814\n",
      "  Class 2: 36383\n",
      "  Class 3: 7065\n",
      "  Class 4: 5088\n",
      "  Class 5: 3808\n",
      "  Class 6: 8309\n",
      "\n",
      "Directory: datasets/valid_filtered/labels\n",
      "  Class 0: 26462\n",
      "  Class 1: 787\n",
      "  Class 2: 4491\n",
      "  Class 3: 901\n",
      "  Class 4: 579\n",
      "  Class 5: 479\n",
      "  Class 6: 958\n",
      "\n",
      "Directory: datasets/test_filtered/labels\n",
      "  Class 0: 26931\n",
      "  Class 1: 769\n",
      "  Class 2: 4575\n",
      "  Class 3: 1055\n",
      "  Class 4: 677\n",
      "  Class 5: 473\n",
      "  Class 6: 1117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Directories to process\n",
    "directories = [\n",
    "    \"datasets/labels\",\n",
    "    \"datasets/train/labels\",\n",
    "    \"datasets/valid/labels\",\n",
    "    \"datasets/test/labels\",\n",
    "    \n",
    "    \"datasets/labels_filtered\",\n",
    "    \"datasets/train_filtered/labels\",\n",
    "    \"datasets/valid_filtered/labels\",\n",
    "    \"datasets/test_filtered/labels\",\n",
    "]\n",
    "\n",
    "def count_labels_in_directory(directory):\n",
    "    \"\"\"\n",
    "    Counts the number of each class in a directory of YOLO label files with a progress bar.\n",
    "    \n",
    "    Args:\n",
    "        directory (str): Path to the directory containing label files.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary with class IDs as keys and counts as values.\n",
    "    \"\"\"\n",
    "    class_counts = defaultdict(int)\n",
    "    \n",
    "    # Get all .txt files in the directory\n",
    "    label_files = [f for f in os.listdir(directory) if f.endswith(\".txt\")]\n",
    "    \n",
    "    # Process each file with a progress bar\n",
    "    with tqdm(total=len(label_files), desc=f\"Processing {directory}\", unit=\"file\") as pbar:\n",
    "        for label_file in label_files:\n",
    "            label_path = os.path.join(directory, label_file)\n",
    "            with open(label_path, \"r\") as file:\n",
    "                for line in file:\n",
    "                    parts = line.split()\n",
    "                    class_id = int(parts[0])  # Extract class ID\n",
    "                    class_counts[class_id] += 1  # Increment the count for the class ID\n",
    "            pbar.update(1)\n",
    "    \n",
    "    return class_counts\n",
    "\n",
    "# Count labels for each directory\n",
    "results = {}\n",
    "\n",
    "for directory in directories:\n",
    "    if os.path.exists(directory):\n",
    "        results[directory] = count_labels_in_directory(directory)\n",
    "    else:\n",
    "        results[directory] = None  # Directory does not exist\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nClass counts per directory:\")\n",
    "for directory, class_counts in results.items():\n",
    "    print(f\"\\nDirectory: {directory}\")\n",
    "    if class_counts is not None:\n",
    "        for class_id, count in sorted(class_counts.items()):\n",
    "            print(f\"  Class {class_id}: {count}\")\n",
    "    else:\n",
    "        print(\"  Directory does not exist or contains no labels.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load YOLO Model and Begin Training!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check for available devices\n",
    "device_name = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "available_devices = torch.cuda.device_count()\n",
    "\n",
    "print(f\"Device in use: {device_name}\")\n",
    "print(f\"Available CUDA devices: {available_devices}\")\n",
    "from ultralytics import YOLO\n",
    "!yolo checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparam tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ultralytics import YOLO\n",
    "# model = YOLO(\"yolo11n.yaml\")\n",
    "# model.tune(\n",
    "#     data=\"train_filtered.yaml\",\n",
    "#     project=\"./hyperparam_tuning3\",\n",
    "#     pretrained=False,  \n",
    "#     epochs = 5,\n",
    "#     iterations=100,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with base hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolo11n.yaml\")\n",
    "model.train(\n",
    "    data=\"train_filtered.yaml\",\n",
    "    project=\"models/base_16\",\n",
    "    pretrained=False,  \n",
    "    epochs = 200,\n",
    "    patience=10, \n",
    "    batch=16,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model32 = YOLO(\"yolo11n.yaml\")\n",
    "model32.train(\n",
    "    data=\"train_filtered.yaml\",\n",
    "    project=\"models/base_32\",\n",
    "    pretrained=False,  \n",
    "    epochs = 200,\n",
    "    patience=10, \n",
    "    batch=32,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "modelX = YOLO(\"yolo11n.yaml\")\n",
    "modelX.train(\n",
    "    data=\"train_filtered.yaml\",\n",
    "    project=\"models/base_X\",\n",
    "    pretrained=False,  \n",
    "    epochs = 200,\n",
    "    patience=10, \n",
    "    batch=-1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with tuned 1 hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model16 = YOLO(\"yolo11n.yaml\")\n",
    "model16.train(\n",
    "    data=\"train_filtered.yaml\",\n",
    "    cfg=\"tunings/tuning1/tune/best_hyperparameters.yaml\",\n",
    "    project=\"models/tuned1_16\",\n",
    "    pretrained=False,  \n",
    "    epochs = 200,\n",
    "    patience=10, \n",
    "    batch=16,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model32 = YOLO(\"yolo11n.yaml\")\n",
    "model32.train(\n",
    "    data=\"train_filtered.yaml\",\n",
    "    cfg=\"tunings/tuning1/tune/best_hyperparameters.yaml\",\n",
    "    project=\"models/tuned1_32\",\n",
    "    pretrained=False,  \n",
    "    epochs = 200,\n",
    "    patience=10, \n",
    "    batch=32,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.82 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.78  Python-3.11.9 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.yaml, data=train_filtered.yaml, epochs=200, time=None, patience=10, batch=-1, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=models/tuned1_X, name=train, exist_ok=False, pretrained=False, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.00938, lrf=0.01068, momentum=0.89665, weight_decay=0.00049, warmup_epochs=2.56713, warmup_momentum=0.37142, warmup_bias_lr=0.1, box=7.93555, cls=0.86648, dfl=1.88871, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.01108, hsv_s=0.84375, hsv_v=0.27844, degrees=0.0, translate=0.11442, scale=0.35418, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.63681, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=tunings/tuning1/tune/best_hyperparameters.yaml, tracker=botsort.yaml, save_dir=models\\tuned1_X\\train\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    432037  ultralytics.nn.modules.head.Detect           [7, [64, 128, 256]]           \n",
      "YOLO11n summary: 181 layers, 2,591,205 parameters, 2,591,189 gradients, 6.4 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir models\\tuned1_X\\train', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Usuario\\Documents\\TFM\\ForeHelm\\training\\COCO\\datasets\\train_filtered\\labels.cache... 59806 images, 38823 backgrounds, 0 corrupt: 100%|██████████| 98629/98629 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640 at 60.0% CUDA memory utilization.\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU) 8.00G total, 0.09G reserved, 0.05G allocated, 7.86G free\n",
      "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
      "     2591205       6.447         0.440         73.64         478.2        (1, 3, 640, 640)                    list\n",
      "     2591205       12.89         0.596         76.09         138.9        (2, 3, 640, 640)                    list\n",
      "     2591205       25.79         0.929         65.01           161        (4, 3, 640, 640)                    list\n",
      "     2591205       51.58         1.569         45.61         112.3        (8, 3, 640, 640)                    list\n",
      "     2591205       103.2         2.840         67.24         149.1       (16, 3, 640, 640)                    list\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 39 for CUDA:0 4.89G/8.00G (61%) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Usuario\\Documents\\TFM\\ForeHelm\\training\\COCO\\datasets\\train_filtered\\labels.cache... 59806 images, 38823 backgrounds, 0 corrupt: 100%|██████████| 98629/98629 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Usuario\\Documents\\TFM\\ForeHelm\\training\\COCO\\datasets\\valid_filtered\\labels... 7504 images, 4824 backgrounds, 0 corrupt: 100%|██████████| 12328/12328 [00:13<00:00, 929.90it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\Usuario\\Documents\\TFM\\ForeHelm\\training\\COCO\\datasets\\valid_filtered\\labels.cache\n",
      "Plotting labels to models\\tuned1_X\\train\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.00938' and 'momentum=0.89665' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005971875), 87 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mmodels\\tuned1_X\\train\u001b[0m\n",
      "Starting training for 200 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/200      6.33G      3.745      8.099      5.149        211        640:  77%|███████▋  | 1946/2529 [11:23<03:24,  2.85it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[0;32m      3\u001b[0m modelX \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolo11n.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mmodelX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain_filtered.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtunings/tuning1/tune/best_hyperparameters.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/tuned1_X\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ultralytics\\engine\\model.py:810\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m    809\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[1;32m--> 810\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ultralytics\\engine\\trainer.py:208\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    205\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 208\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ultralytics\\engine\\trainer.py:393\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[1;34m(self, world_size)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;66;03m# Optimize - https://pytorch.org/docs/master/notes/amp_examples.html\u001b[39;00m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ni \u001b[38;5;241m-\u001b[39m last_opt_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccumulate:\n\u001b[1;32m--> 393\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    394\u001b[0m     last_opt_step \u001b[38;5;241m=\u001b[39m ni\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;66;03m# Timed stopping\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ultralytics\\engine\\trainer.py:591\u001b[0m, in \u001b[0;36mBaseTrainer.optimizer_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39munscale_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer)  \u001b[38;5;66;03m# unscale gradients\u001b[39;00m\n\u001b[0;32m    590\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10.0\u001b[39m)  \u001b[38;5;66;03m# clip gradients\u001b[39;00m\n\u001b[1;32m--> 591\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\amp\\grad_scaler.py:457\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[1;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    455\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 457\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    459\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\amp\\grad_scaler.py:351\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[1;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    345\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m    350\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(v\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m    352\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\amp\\grad_scaler.py:351\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    345\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m    350\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m    352\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "modelX = YOLO(\"yolo11n.yaml\")\n",
    "modelX.train(\n",
    "    data=\"train_filtered.yaml\",\n",
    "    cfg=\"tunings/tuning1/tune/best_hyperparameters.yaml\",\n",
    "    project=\"models/tuned1_X\",\n",
    "    pretrained=False,  \n",
    "    epochs = 200,\n",
    "    patience=10, \n",
    "    batch=-1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with tuned 2 hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model16 = YOLO(\"yolo11n.yaml\")\n",
    "model16.train(\n",
    "    data=\"train_filtered.yaml\",\n",
    "    cfg=\"tunings/tuning2/tune/best_hyperparameters.yaml\",\n",
    "    project=\"models/tuned2_16\",\n",
    "    pretrained=False,  \n",
    "    epochs = 200,\n",
    "    patience=10, \n",
    "    batch=16,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model32 = YOLO(\"yolo11n.yaml\")\n",
    "model32.train(\n",
    "    data=\"train_filtered.yaml\",\n",
    "    cfg=\"tunings/tuning2/tune/best_hyperparameters.yaml\",\n",
    "    project=\"models/tuned2_32\",\n",
    "    pretrained=False,  \n",
    "    epochs = 200,\n",
    "    patience=10, \n",
    "    batch=32,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "modelX = YOLO(\"yolo11n.yaml\")\n",
    "modelX.train(\n",
    "    data=\"train_filtered.yaml\",\n",
    "    cfg=\"tunings/tuning2/tune/best_hyperparameters.yaml\",\n",
    "    project=\"models/tuned2_X\",\n",
    "    pretrained=False,  \n",
    "    epochs = 200,\n",
    "    patience=10, \n",
    "    batch=-1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "model16 = YOLO(\"models/base_16/train/weights/last.pt\")\n",
    "model16.train(resume=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating the YOLO models\n",
    "The following code is used to validate and compare the different YOLO models that have been trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code tries the default and pretrained yolo11n model with the COCO dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# List of model weight paths\n",
    "weights_paths = [\n",
    "    \"yolo11n.pt\",\n",
    "    \"models/base_16/train/weights/best.pt\",\n",
    "    \"models/base_32/train/weights/best.pt\",\n",
    "    \"models/base_X/train/weights/best.pt\",\n",
    "    \"models/tuned1_16/train/weights/best.pt\",\n",
    "    \"models/tuned1_32/train2/weights/best.pt\",\n",
    "    \"models/tuned21_X/train/weights/best.pt\",\n",
    "    \"models/tuned2_16/train/weights/best.pt\",\n",
    "    \"models/tuned2_32/train/weights/best.pt\",\n",
    "    \"models/tuned2_X/train/weights/best.pt\"\n",
    "]\n",
    "\n",
    "# Corresponding project names for each model\n",
    "prj_paths = [\n",
    "    \"yolo11n\",\n",
    "    \"models/base_16\",\n",
    "    \"models/base_32\",\n",
    "    \"models/base_X\",\n",
    "    \"models/tuned1_16\",\n",
    "    \"models/tuned1_32\",\n",
    "    \"models/tuned21_X\",\n",
    "    \"models/tuned2_16\",\n",
    "    \"models/tuned2_32\",\n",
    "    \"models/tuned2_X\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your dataset configuration file\n",
    "data_path = \"train_filtered.yaml\"\n",
    "# Device to run the validation on (e.g., '0' for the first GPU, 'cpu' for CPU)\n",
    "device = \"0\"\n",
    "# Dictionary to store validation results\n",
    "validation_results = {}\n",
    "\n",
    "# Iterate over each model weight path and its corresponding project name\n",
    "for weights_path, prj_path in zip(weights_paths, prj_paths):\n",
    "    # Load the model\n",
    "    model = YOLO(weights_path)    \n",
    "    # Perform validation\n",
    "    results = model.val(data=data_path, project=prj_path, device=device, save_json=True, save=False)\n",
    "    # Extract relevant metrics\n",
    "    metrics = {\n",
    "        'mAP50': results.box.map50,\n",
    "        'mAP50-95': results.box.map,\n",
    "        'mAP75': results.box.map75,\n",
    "        'mAPs': results.box.maps\n",
    "    }\n",
    "    # Store metrics in the dictionary\n",
    "    validation_results[prj_path] = metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(validation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.utils.benchmarks import benchmark\n",
    "benchmark_results = {}\n",
    "for weights_path, prj_path in zip(weights_paths, prj_paths):\n",
    "    # Benchmark specific export format\n",
    "    benchmark_results[prj_path] = benchmark(model=weights_path, data=data_path, imgsz=640, format=\"ncnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "for weights_path in weights_paths:\n",
    "    # Load the model\n",
    "    model = YOLO(weights_path)\n",
    "    # Export the model to NCNN format\n",
    "    model.export(format=\"ncnn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your dataset configuration file\n",
    "data_path = \"train_filtered.yaml\"\n",
    "# Device to run the validation on (e.g., '0' for the first GPU, 'cpu' for CPU)\n",
    "device = \"0\"\n",
    "# Dictionary to store validation results\n",
    "validation_results_ncnn = {}\n",
    "\n",
    "# Iterate over each model weight path and its corresponding project name\n",
    "for weights_path, prj_path in zip(weights_ncnn_paths, prj_paths):\n",
    "    # Load the model\n",
    "    model = YOLO(weights_path)\n",
    "    \n",
    "    # Perform validation\n",
    "    results = model.val(data=data_path, project=prj_path, name=\"val_ncnn\",device=device, save_json=True, save=False)\n",
    "    \n",
    "    # Extract relevant metrics\n",
    "    metrics = {\n",
    "        'mAP50': results.box.map50,\n",
    "        'mAP50-95': results.box.map,\n",
    "        'mAP75': results.box.map75,\n",
    "        'mAPs': results.box.maps\n",
    "    }\n",
    "    \n",
    "    # Store metrics in the dictionary\n",
    "    validation_results_ncnn[weights_path] = metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.utils.prune as prune\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "def prune_model_l1(model, amount=0.2):\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            prune.l1_unstructured(module, name='weight', amount=amount)\n",
    "            prune.remove(module, 'weight')\n",
    "    return model\n",
    "\n",
    "def prune_model_l2(model, amount=0.2):\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            prune.l2_unstructured(module, name='weight', amount=amount)\n",
    "            prune.remove(module, 'weight')\n",
    "    return model\n",
    "\n",
    "def prune_model_global(model, amount=0.2):\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            prune.global_unstructured(module, name='weight', amount=amount)\n",
    "            prune.remove(module, 'weight')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the YOLO model\n",
    "weights = \"models/tuned1_16/train/weights/best.pt\"\n",
    "model = YOLO(weights)\n",
    "\n",
    "# Validate the original model (optional)\n",
    "# result = model.val(data=\"train_filtered.yaml\")\n",
    "print(\"Original model validation completed.\")\n",
    "torch_model = model.model\n",
    "print(torch_model)\n",
    "\n",
    "results_l1 = {}\n",
    "results_l2 = {}\n",
    "results_global = {}\n",
    "\n",
    "for i in np.arange(0.01, 0.21, 0.02):\n",
    "    # Prune the model by updating the model's internal torch model in place\n",
    "    print(\"Pruning model...\")\n",
    "    pruned_model = prune_model_l1(torch_model, amount=i)\n",
    "    print(f\"Model pruned for {i}.\")\n",
    "    model.model = pruned_model\n",
    "    # Validate the pruned model using the same YOLO validation method\n",
    "    result = model.val(data=\"train_filtered.yaml\")\n",
    "    results_l1[str(i)] =  result\n",
    "    print(f\"Pruned model validation completed for {i}.\")\n",
    "\n",
    "\n",
    "for i in np.arange(0.01, 0.21, 0.02):\n",
    "    # Prune the model by updating the model's internal torch model in place\n",
    "    print(\"Pruning model...\")\n",
    "    pruned_model = prune_model_l2(torch_model, amount=i)\n",
    "    print(f\"Model pruned for {i}.\")\n",
    "    model.model = pruned_model\n",
    "    # Validate the pruned model using the same YOLO validation method\n",
    "    result = model.val(data=\"train_filtered.yaml\")\n",
    "    results_l2[str(i)] =  result\n",
    "    print(f\"Pruned model validation completed for {i}.\")\n",
    "\n",
    "\n",
    "for i in np.arange(0.01, 0.21, 0.02):\n",
    "    # Prune the model by updating the model's internal torch model in place\n",
    "    print(\"Pruning model...\")\n",
    "    pruned_model = prune_model_global(torch_model, amount=i)\n",
    "    print(f\"Model pruned for {i}.\")\n",
    "    model.model = pruned_model\n",
    "    # Validate the pruned model using the same YOLO validation method\n",
    "    result = model.val(data=\"train_filtered.yaml\")\n",
    "    results_global[str(i)] =  result\n",
    "    print(f\"Pruned model validation completed for {i}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_l1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_l2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"base_40/train/weights/best.pt\")\n",
    "results = model.val(data=\"train_filtered.yaml\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
